{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling SCS in Parallel\n",
    "\n",
    "In this notebook, we set up a list of several SCS problems and map `scs.solve` over that list\n",
    "to solve each of the problems.\n",
    "\n",
    "- Our first attempt uses Python's builtin `map` function, which operates in serial, solving one problem at a time.\n",
    "- The second attempt uses `concurrent.futures.ProcessPoolExecutor` to solve the problems in parallel, using separate Python processes.\n",
    "- The final attempt uses `concurrent.futures.ThreadPoolExecutor` to solve in parallel, using separate threads.\n",
    "\n",
    "When running arbitrary Python code, the `ThreadPoolExecutor` approach may suffer due to the Python GIL, which  prevents multiple threads from executing at the same time. However, SCS is able to release the GIL when running its underlying C code, allowing it to achieve true parallelism and performance similar to `ProcessPoolExecutor`. \n",
    "\n",
    "The ThreadPool approach may be preferable to ProcessPool because it doesn't require launching separate Python interpreters for each process, and does not need to serialize data to communicate it between processes.\n",
    "\n",
    "This notebook uses the `concurrent.futures` library, which is new to Python 3.2, but has been backported to Python 2.5 and above through the [`futures` libray on PyPi](https://pypi.python.org/pypi/futures)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data\n",
    "\n",
    "We first generate a number of SCS problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scs\n",
    "from concurrent import futures\n",
    "\n",
    "num_problems = 20\n",
    "m = 1000 # size of L1 problem\n",
    "\n",
    "data = [scs.examples.l1(m, seed=i) for i in range(num_problems)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a `solve` function to map over our problem data.\n",
    "We set `verbose=False` because verbose printing can hinder performance, because the GIL needs to be reacquired for each print.\n",
    "We define a function instead of a lambda because `ProcessPoolExecutor` can't serialize lambdas.\n",
    "\n",
    "We set the number of **workers** to 4 in this example, which will set the number of threads or processes in the parallel examples. Setting the number of workers to be the number of processors on your system is a good first guess, but some experimentation may be required to find the optimal setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "workers = 4 # number of threads/processes\n",
    "\n",
    "def solve(x):\n",
    "    return scs.solve(*x, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serial solve with `map`\n",
    "\n",
    "We observe the solvetime in serial, using the builtin Python `map` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.3 s, sys: 201 ms, total: 36.5 s\n",
      "Wall time: 36.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a = list(map(solve, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel solve with processes\n",
    "\n",
    "We observe the parallel solvetime, using `ProcessPoolExecutor.map()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 128 ms, sys: 154 ms, total: 282 ms\n",
      "Wall time: 23.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with futures.ProcessPoolExecutor(workers) as ex:\n",
    "    a = list(ex.map(solve, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel solve with threads\n",
    "\n",
    "We observe the parallel solvetime, using `ThreadPoolExecutor.map()`.\n",
    "\n",
    "We achieve similar performance to the processes example because SCS releases the GIL when calling its underlying C solver code. Threads can be more lightweight than processes because they do not need to launch separate Python interpreters, and do not need to serialize data to communicate between processes.\n",
    "However, in this case, it doesn't seem to help much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 25s, sys: 538 ms, total: 1min 25s\n",
      "Wall time: 22.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with futures.ThreadPoolExecutor(workers) as ex:\n",
    "    a = list(ex.map(solve, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCS `Workspace` in parallel\n",
    "\n",
    "We can also form `scs.Workspace` objects in parallel, and use them to solve problems in parallel.\n",
    "\n",
    "Below, we define two functions to form and solve with `Workspace`, which we'll use in our serial and parallel maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def form_workspace(x):\n",
    "    return scs.Workspace(*x, verbose=False)\n",
    "\n",
    "def workspace_solve(work):\n",
    "    return work.solve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize `Workspace`\n",
    "\n",
    "We can compare the intialization time (which involves a matrix factorization) for the `Workspace` objects when we perform it in serial and in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.36 s, sys: 169 ms, total: 9.53 s\n",
      "Wall time: 9.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "workspaces = list(map(form_workspace, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.2 s, sys: 496 ms, total: 24.7 s\n",
      "Wall time: 6.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with futures.ThreadPoolExecutor(workers) as ex:\n",
    "    workspaces = list(ex.map(form_workspace, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Workspace.solve()`\n",
    "\n",
    "We can also compare serial and parallel calls of `workspace.solve()`.\n",
    "\n",
    "Note that we **can't** use `ProcessPoolExecutor` here, because it can't serialize SCS `Workspace` objects.\n",
    "`ThreadPoolExecutor` eliminates the need for serialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.5 s, sys: 87.4 ms, total: 26.6 s\n",
      "Wall time: 26.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = list(map(workspace_solve, workspaces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min, sys: 215 ms, total: 1min 1s\n",
      "Wall time: 16.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with futures.ThreadPoolExecutor(workers) as ex:\n",
    "    results = list(ex.map(workspace_solve, workspaces))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
